<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MultiRef: Controllable Image Generation with Multiple Visual References">
  <meta name="keywords" content="Controllable image generation, multi-images-to-image, unified models, Benchmark, Dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MultiRef: Controllable Image Generation with Multiple Visual References</title>
  <script type="module" src="https://md-block.verou.me/md-block.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./img/gui-logo.jpg">

  <link rel="stylesheet" href="./stylesheets/layout.css">
  <link rel="stylesheet" href="./stylesheets/index.css">
  <link rel="stylesheet" href="./bowe_componets/css/bootstrap.table.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./static/css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="./static/css/custom.css" media="screen" rel="stylesheet" type="text/css" />
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://dongping-chen.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://trustllmbenchmark.github.io/TrustLLM-Website/">
              TrustLLM
            </a>
            <a class="navbar-item" href="https://mllm-judge.github.io">
              MLLM-as-a-Judge
            </a>
            <a class="navbar-item" href="https://unigen-framework.github.io/">
              UniGen
            </a>
            <a class="navbar-item" href="https://github.com/Flossiee/HonestyLLM">
              HonestyLLM
            </a>
            <a class="navbar-item" href="https://llm-coauthor.github.io/">
              LLM-as-a-Coauthor
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              MultiRef: Controllable Image Generation with Multiple Visual References
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://siyuan-5.github.io/">Ruoxi Chen<a></a><sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block"><a href="https://dongping-chen.github.io/">Dongping
                Chen</a></a><sup style="color:#fabb55;">1</sup><sup style="color:#ec8bfd;">2</sup><sup style="color:#0cd5b7;">‡</sup>,</span> 
              <span class="author-block"><a href="https://siyuan-5.github.io/">Siyuan Wu<a></a><sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block">Sinan Wang<sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block">Shiyun Lang<sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block">Petr Sushku<sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block">Gaoyang Jiang<sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block"><a href="http://wanyao.me/"><b>Yao Wan</b></a><sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=CQ1cqKkAAAAJ&hl=en"><b>Ranjay Krishna</b></a><sup style="color:#fabb55;">1</sup><sup style="color:#c9892e;">†</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#fabb55;">1</sup>University of Washington,</span>
              <br>
              <span class="author-block"><sup style="color:#ec8bfd;">2</sup>Huazhong University of Science and Technology,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">{<a href="mailto:dipsy0830@gmail.com">dipsy0830</a>,<a href="mailto:dongpingchen0612@gmail.com">dongpingchen0612</a>}@gmail.com, <a href="mailto:ranjay@cs.washington.edu">ranjay@cs.washington.edu</a></span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fas fa-file-pdf"></i>-->
                <!--                    </span>-->
                <!--                    <span>Paper</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1Kdj0pvpjbYNuYxzprzNUc4cytZme5rKg/view?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/Dipsy0830/MultiRef-code"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1J7cNpWPlkOTgwboo62Jx81IHx137TP2c/view?usp=sharing"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google-drive"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/wsnHowest/multiref/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Realistic Benchmark</span>
                  </a>
                </span>
                <!-- Data Viewer. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/Dipsy0830/MultiRef" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-images"></i>
                    </span>
                    <span>Synthetic Benchmark</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/Dipsy0830/MultiRef" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-desktop"></i>
                    </span>
                    <span>Dataset (38k)</span>
                  </a>
                </span>
                <!-- Slides Link. -->
                <!-- <span class="link-block">
                  <a href="https://docs.google.com/presentation/d/1-r889Nb9n7SeZqrj-ryNqJLoMzp7aGNU2ihO8nUdEcE/edit?usp=sharing"
                    target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google"></i>
                    </span>
                    <span>Slides</span>
                  </a>
                </span> -->
                <!-- Twitter Link. -->
                <!-- <span class="link-block">
                  <a href="https://twitter.com/TianbaoX/status/1778781521253667267" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-twitter"></i>
                    </span>
                    <span>Twitter</span>
                  </a>
                </span> -->
                <!-- Discord Link. -->
                <!-- <span class="link-block">
                  <a href="https://discord.gg/4Gnw7eTEZR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-discord"></i>
                    </span>
                    <span>Discord</span>
                  </a>
                </span> -->

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <video controls muted loop autoplay width="100%">
          <source src="static/videos/main.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Main Figure. -->
      <h2 class="title is-3"></h2>
      <div class="content has-text-justified">
        <img src="img/MultiRef-Case-Study.png" width="100%" alt="MultiRef Overview" class="responsive-image">
        <img src="img/MultiRef-radar.png" width="100%" alt="MultiRef Benchmark Overview" class="responsive-image">
        <md-block>
          **MultiRef** introduces the first comprehensive benchmark for evaluating image generation models' ability to combine multiple visual references, revealing that even state-of-the-art models struggle significantly with multi-reference conditioning compared to single-reference tasks.
          <ol>
            <li><b>Novel Task and Benchmark Creation:</b> The paper introduces <b>MultiRef-Bench</b>, comprising 990 synthetic and 1,000 real-world generation samples that require incorporating visual content from multiple reference images. The benchmark includes a sophisticated synthetic data engine (<b>RefBlend</b>) that generates diverse training samples across 10 reference types (depth maps, sketches, masks, etc.) and 32 reference combinations, with compatibility rules to ensure meaningful combinations. </li>
            <li><b>Comprehensive Evaluation Framework:</b> The authors develop a robust evaluation methodology combining rule-based metrics (IoU for spatial references, MSE for structural references) and a fine-tuned MLLM-as-a-Judge model for semantic assessments. Testing reveals that the best-performing model (<b>OmniGen</b>) achieves only 66.6% on synthetic samples and 79.0% on real-world cases compared to golden answers, exposing significant gaps in current models' multi-reference capabilities. </li>
            <li><b>Critical Findings on Model Limitations:</b> While compositional frameworks (LLM + diffusion models) excel in image quality, they fail to maintain consistency with source images and instructions. Unified models show better controllability but struggle with generation quality. Most critically, all models face severe challenges when visual references are complexly mixed, often producing corrupted outputs, indicating that current architectures are not truly equipped for the multi-reference creative processes inherent to human artistic expression.</li>
          </ol>
        </md-block>
      </div>
      <!--/ Main Figure. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <md-block>
              Visual designers naturally draw inspiration from multiple visual
              references, combining diverse elements and aesthetic principles to
              create artwork. However, current image generative frameworks
              predominantly rely on single-source inputs — either text prompts
              or individual reference images. In this paper, we focus on the task
              of controllable image generation using multiple visual references.
              We introduce MultiRef-bench, a rigorous evaluation framework
              comprising 990 synthetic and 1,000 real-world generation samples
              that require incorporating visual content from multiple reference
              images. The synthetic samples are synthetically generated through
              our data engine RefBlend, with 10 reference types and 33 ref-
              erence combinations. Based on RefBlend, we further construct
              a dataset MultiRef containing 38k high-quality images to facil-
              itate further research. Our experiments across three interleaved
              image-text models (i.e., OmniGen, ACE, and Show-o) and six agentic
              frameworks (e.g., ChatDiT and LLM + SD) reveal that even state-of-
              the-art systems struggle with multi-reference conditioning, with
              the best model OmniGen achieving only 66.6% in synthetic samples
              and 79.0% in real-world cases on average compared to the golden
              answer. These findings provide valuable directions for developing
              more flexible and human-like creative tools that can effectively inte-
              grate multiple sources of visual inspiration.
            </md-block>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Environment Infrastructure. -->
      <h2 class="title is-3">MultiRef Dataset Construction</h2>
      <div class="content has-text-justified">
        <img src="img/MultiRef-data-construction.png" width="100%" alt="environment infrastructure" class="responsive-image">
        <md-block>
          We introduce **MultiRef**, a comprehensive dataset for multi-reference image generation, comprising 38,076 high-quality images designed to facilitate controllable image generation using multiple visual references. The dataset encompasses diverse reference types including depth maps, semantic segmentation, Canny edges, sketches, bounding boxes, masks, human poses, art styles, subjects, and textual captions, with 33 different reference combinations across 10 distinct reference modalities. These references span various visual domains from architectural photography and artistic paintings to human-centric imagery and abstract compositions, enabling comprehensive evaluation of multi-reference conditioning capabilities.
          The construction of the MultiRef dataset follows a dual-pipeline methodology:
          <ol>
          <li><b>Real-World Data Collection from Community Platforms</b>: We collect authentic multi-reference tasks from Reddit's r/PhotoshopRequest community, following established practices for real-world image editing scenarios. This process involves gathering 2,300 user-submitted queries that require combining multiple input images, followed by rigorous manual evaluation to ensure data quality by verifying image necessity, instruction coherence, and output accuracy. Each datapoint includes 2-6 input images, structured instructions, and professional-quality output images, with final selection yielding 1,000 high-quality real-world examples.</li>
          <li><b>Synthetic Data Generation via RefBlend Engine</b>: To address the scarcity of multi-reference training data, we develop RefBlend, a novel four-step synthetic data engine that automatically produces diverse samples. The process includes: (1) extracting comprehensive visual references from original images using state-of-the-art models (<em>e.g.</em>, Grounded SAM2, Depth Anything2), (2) establishing compatibility rules and generating valid reference combinations based on visual reference dependencies, (3) creating both structured and enhanced instruction prompts using template-based approaches and GPT-4o persona-driven variations, and (4) implementing a high-quality filtering pipeline combining rule-based metrics and fine-tuned MLLM-as-a-Judge assessment to ensure only the most relevant and effective examples are included in the final dataset.</li>
          </ol>
          </md-block>
      </div>
      <!--/ Environment Infrastructure. -->
    </div>
  </section>

  <section>
    <div class="container is-max-desktop">

      <h2 class="title is-3">Benchmark</h2>
      <md-block>
        We conduct evaluations on three state-of-the-art unified image generation models: <strong>OmniGen</strong>, <strong>ACE</strong>, and <strong>Show-o</strong>. Additionally, we evaluate six compositional frameworks that leverage large language models as perceptors combined with diffusion models as generators, including <strong>ChatDiT</strong>, <strong>Claude + SD</strong> (versions 2.1, 3, 3.5), and <strong>Gemini + SD</strong> (versions 2.1, 3, 3.5).
        <br><br>
        For multi-reference conditioning, unified models implement multi-turn dialogues where each conversational turn incorporates one reference image, while compositional frameworks process all references simultaneously through structured prompts.
        <br><br>
        Our evaluation employs a comprehensive three-dimensional assessment framework: (1) <strong>Reference Fidelity</strong>, measuring how accurately generated images preserve specific attributes from provided references using both rule-based metrics (IoU, MSE) and model-based assessments; (2) <strong>Image Quality</strong>, evaluating visual fidelity through FID scores and aesthetic appeal via CLIP aesthetic scores; and (3) <strong>Overall Assessment</strong>, utilizing fine-tuned MLLM-as-a-Judge (GPT-4o-mini) to holistically evaluate Image Quality (IQ), Instruction Following (IF), and Source Fidelity (SF) on a 1-5 scale.
        <br><br>
        For reference-specific evaluation, we employ specialized metrics tailored to each modality: IoU for spatial constraints (bounding boxes, semantic maps, masks), MSE for structural fidelity (depth maps, Canny edges, sketches), CLIP scores for semantic consistency (subjects, art styles), and mAP for pose accuracy. All metrics are normalized to [0,1] range for consistency.
        <br><br>
        <strong>We evaluate on both synthetic samples (990 examples) and real-world tasks (1,000 examples) to ensure comprehensive assessment across diverse multi-reference scenarios.</strong>
      </md-block>
    </div>
    <div class="cover" id="contentCover">
      <!-- Baseline. -->
      <div class="container-t">
        <div class="row">
          <div class="col-md-12">
            <div class="infoCard">
              <div class="infoBody">
                <div class="tabs is-centered example_lst">
                  <ul>
                    <li class="is-active"><a title="Synthetic Part">Synthetic Benchmark Performance</a></li>
                    <li><a title="Realistic Part">Realistic Benchmark Performance</a></li>
                    <li><a title="Case Study">MLLM-as-a-Judge Validation</a></li>
                    <li><a title="Ablation Study">Ablation Study</a></li>
                  </ul>

                </div>
                <script type="text/javascript">
                  document.querySelectorAll(".example_lst li").forEach(e => {
                    e.addEventListener("click", Click_1)
                  })

                  function Click_1(eve) {
                    const iTxt = eve.srcElement.innerText
                    for (let v of document.querySelectorAll(".example_lst a")) {
                      if (iTxt === v.innerText) {
                        v.parentElement.className = "is-active";
                      } else {
                        v.parentElement.className = "";
                      }
                    }
                    for (let block of document.getElementsByClassName('lib_examples')) {
                      block.style.display = (block.title === iTxt) ? 'block' : 'none';
                    }
                  }

                </script>
                <div title="Synthetic Benchmark Performance" class="lib_examples" id="BoardPanel1" style="display: none;">
                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Notice: Avg. = Average, MC = Multiple-Choice QA, Free = Free-Form QA, R. = Random, E. = Extracted, H. = Human-Selected
                  </md-block>
                  <!-- </div> -->
                  <div class="table-container">
              <table>
                <thead>
                  <tr>
                    <th rowspan="2">Model Type</th>
                    <th rowspan="2">Model</th>
                    <th colspan="3">Overall Assessment</th>
                    <th colspan="2">Image Quality</th>
                    <th colspan="10">Reference Fidelity</th>
                  </tr>
                  <tr>
                    <th>IQ</th>
                    <th>IF</th>
                    <th>SF</th>
                    <th>FID↓</th>
                    <th>Aesthetic↑</th>
                    <th>BBox↑</th>
                    <th>Semantic Map↑</th>
                    <th>Mask↑</th>
                    <th>Depth↓</th>
                    <th>Canny↓</th>
                    <th>Sketch↓</th>
                    <th>Caption↑</th>
                    <th>Pose↑</th>
                    <th>Subject↑</th>
                    <th>Art Style↑</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <th rowspan="3">Unified Models</th>
                    <th>Show-o</th>
                    <td>0.764</td>
                    <td>0.616</td>
                    <td>0.462</td>
                    <td>0.110</td>
                    <td>0.607</td>
                    <td>0.051</td>
                    <td>0.263</td>
                    <td>0.332</td>
                    <td>0.104</td>
                    <td>0.061</td>
                    <td>0.203</td>
                    <td>0.569</td>
                    <td>0.008</td>
                    <td>0.532</td>
                    <td>0.301</td>
                  </tr>
                  <tr>
                    <th>OmniGen</th>
                    <td>0.730</td>
                    <td>0.532</td>
                    <td>0.438</td>
                    <td>0.111</td>
                    <td>0.593</td>
                    <td>0.179</td>
                    <td>0.197</td>
                    <td>0.320</td>
                    <td>0.087</td>
                    <td>0.092</td>
                    <td>0.221</td>
                    <td>0.382</td>
                    <td>0.014</td>
                    <td>0.623</td>
                    <td>0.329</td>
                  </tr>
                  <tr>
                    <th>ACE</th>
                    <td>0.740</td>
                    <td>0.655</td>
                    <td>0.528</td>
                    <td>0.108</td>
                    <td>0.592</td>
                    <td>0.219</td>
                    <td>0.382</td>
                    <td>0.439</td>
                    <td>0.044</td>
                    <td>0.079</td>
                    <td>0.112</td>
                    <td>0.521</td>
                    <td>0.090</td>
                    <td>0.720</td>
                    <td>0.397</td>
                  </tr>
                  <tr>
                    <th rowspan="7">Compositional Frameworks</th>
                    <th>ChatDiT</th>
                    <td>0.811</td>
                    <td>0.713</td>
                    <td>0.574</td>
                    <td>0.100</td>
                    <td>0.559</td>
                    <td>0.128</td>
                    <td>0.176</td>
                    <td>0.393</td>
                    <td>0.088</td>
                    <td>0.065</td>
                    <td>0.207</td>
                    <td>0.543</td>
                    <td>0.018</td>
                    <td>0.855</td>
                    <td>0.369</td>
                  </tr>
                  <tr>
                    <th>Claude + SD 2.1</th>
                    <td>0.812</td>
                    <td>0.726</td>
                    <td>0.572</td>
                    <td>0.114</td>
                    <td>0.612</td>
                    <td>0.174</td>
                    <td>0.132</td>
                    <td>0.292</td>
                    <td>0.203</td>
                    <td>0.080</td>
                    <td>0.230</td>
                    <td>0.547</td>
                    <td>0.005</td>
                    <td>0.817</td>
                    <td>0.424</td>
                  </tr>
                  <tr>
                    <th>Claude + SD 3</th>
                    <td>0.876</td>
                    <td>0.817</td>
                    <td>0.658</td>
                    <td>0.102</td>
                    <td>0.635</td>
                    <td>0.134</td>
                    <td>0.145</td>
                    <td>0.360</td>
                    <td>0.203</td>
                    <td>0.087</td>
                    <td>0.215</td>
                    <td>0.576</td>
                    <td>0.009</td>
                    <td>0.859</td>
                    <td>0.420</td>
                  </tr>
                  <tr>
                    <th><b>Claude + SD 3.5</b></th>
                    <td><b>0.913</b></td>
                    <td><b>0.853</b></td>
                    <td><b>0.691</b></td>
                    <td>0.111</td>
                    <td><b>0.647</b></td>
                    <td>0.124</td>
                    <td>0.147</td>
                    <td>0.358</td>
                    <td>0.082</td>
                    <td>0.082</td>
                    <td>0.213</td>
                    <td>0.573</td>
                    <td>0.009</td>
                    <td>0.858</td>
                    <td>0.434</td>
                  </tr>
                  <tr>
                    <th>Gemini + SD 2.1</th>
                    <td>0.791</td>
                    <td>0.708</td>
                    <td>0.547</td>
                    <td>0.113</td>
                    <td>0.615</td>
                    <td>0.161</td>
                    <td>0.133</td>
                    <td>0.255</td>
                    <td>0.202</td>
                    <td>0.092</td>
                    <td>0.239</td>
                    <td>0.550</td>
                    <td>0.003</td>
                    <td>0.791</td>
                    <td>0.406</td>
                  </tr>
                  <tr>
                    <th>Gemini + SD 3</th>
                    <td>0.856</td>
                    <td>0.804</td>
                    <td>0.639</td>
                    <td>0.103</td>
                    <td>0.635</td>
                    <td>0.141</td>
                    <td>0.135</td>
                    <td>0.368</td>
                    <td>0.083</td>
                    <td>0.121</td>
                    <td>0.216</td>
                    <td>0.581</td>
                    <td>0.008</td>
                    <td>0.840</td>
                    <td>0.414</td>
                  </tr>
                  <tr>
                    <th>Gemini + SD 3.5</th>
                    <td>0.893</td>
                    <td>0.839</td>
                    <td>0.676</td>
                    <td>0.111</td>
                    <td>0.646</td>
                    <td>0.132</td>
                    <td>0.130</td>
                    <td>0.371</td>
                    <td>0.077</td>
                    <td>0.096</td>
                    <td>0.216</td>
                    <td>0.579</td>
                    <td>0.008</td>
                    <td>0.845</td>
                    <td>0.422</td>
                  </tr>
                  <tr>
                    <th>Ground Truth</th>
                    <th>-</th>
                    <td>0.842</td>
                    <td>0.803</td>
                    <td>0.668</td>
                    <td>0.108</td>
                    <td>0.617</td>
                    <td><b>0.410</b></td>
                    <td><b>0.772</b></td>
                    <td><b>0.893</b></td>
                    <td><b>0.000</b></td>
                    <td><b>0.000</b></td>
                    <td><b>0.000</b></td>
                    <td>0.584</td>
                    <td><b>0.149</b></td>
                    <td><b>0.869</b></td>
                    <td>0.417</td>
                  </tr>
                </tbody>
              </table>
                  </div>
                </div>

                <div title="Realistic Benchmark Performance" class="lib_examples" id="BoardPanel2" style="display: none;">
                  <!-- <div class="content has-text-justified"> -->
                  <!-- </div> -->

                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Model Type</th>
                          <th rowspan="2">Model</th>
                          <th colspan="3">Element Addition</th>
                          <th colspan="3">Spatial Manipulations</th>
                          <th colspan="3">Element Replacement</th>
                          <th colspan="3">Attribute Transfer</th>
                          <th colspan="3">Style Modifications</th>
                          <th colspan="3">Overall</th>
                        </tr>
                        <tr>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th rowspan="3">Unified Models</th>
                          <th>Show-o</th>
                          <td>0.511</td>
                          <td>0.290</td>
                          <td>0.253</td>
                          <td>0.525</td>
                          <td>0.300</td>
                          <td>0.258</td>
                          <td>0.508</td>
                          <td>0.268</td>
                          <td>0.240</td>
                          <td>0.548</td>
                          <td>0.301</td>
                          <td>0.260</td>
                          <td>0.473</td>
                          <td>0.307</td>
                          <td>0.259</td>
                          <td>0.513</td>
                          <td>0.293</td>
                          <td>0.254</td>
                        </tr>
                        <tr>
                          <th>OmniGen</th>
                          <td>0.553</td>
                          <td>0.498</td>
                          <td>0.429</td>
                          <td>0.553</td>
                          <td>0.461</td>
                          <td>0.422</td>
                          <td>0.484</td>
                          <td>0.450</td>
                          <td>0.379</td>
                          <td>0.567</td>
                          <td>0.479</td>
                          <td>0.408</td>
                          <td>0.620</td>
                          <td>0.590</td>
                          <td>0.468</td>
                          <td>0.555</td>
                          <td>0.496</td>
                          <td>0.421</td>
                        </tr>
                        <tr>
                          <th>ACE</th>
                          <td>0.254</td>
                          <td>0.207</td>
                          <td>0.205</td>
                          <td>0.260</td>
                          <td>0.207</td>
                          <td>0.205</td>
                          <td>0.255</td>
                          <td>0.207</td>
                          <td>0.203</td>
                          <td>0.234</td>
                          <td>0.200</td>
                          <td>0.200</td>
                          <td>0.265</td>
                          <td>0.205</td>
                          <td>0.200</td>
                          <td>0.254</td>
                          <td>0.205</td>
                          <td>0.203</td>
                        </tr>
                        <tr>
                          <th rowspan="7">Compositional Frameworks</th>
                          <th>ChatDiT</th>
                          <td>0.629</td>
                          <td>0.390</td>
                          <td>0.345</td>
                          <td>0.643</td>
                          <td>0.411</td>
                          <td>0.352</td>
                          <td>0.643</td>
                          <td>0.434</td>
                          <td>0.360</td>
                          <td>0.682</td>
                          <td>0.466</td>
                          <td>0.395</td>
                          <td>0.688</td>
                          <td>0.522</td>
                          <td>0.424</td>
                          <td>0.657</td>
                          <td>0.445</td>
                          <td>0.375</td>
                        </tr>
                        <tr>
                          <th>Gemini + SD 2.1</th>
                          <td>0.611</td>
                          <td>0.372</td>
                          <td>0.329</td>
                          <td>0.620</td>
                          <td>0.404</td>
                          <td>0.324</td>
                          <td>0.574</td>
                          <td>0.391</td>
                          <td>0.339</td>
                          <td>0.605</td>
                          <td>0.397</td>
                          <td>0.332</td>
                          <td>0.660</td>
                          <td>0.495</td>
                          <td>0.385</td>
                          <td>0.614</td>
                          <td>0.412</td>
                          <td>0.342</td>
                        </tr>
                        <tr>
                          <th>Claude + SD 2.1</th>
                          <td>0.620</td>
                          <td>0.402</td>
                          <td>0.330</td>
                          <td>0.625</td>
                          <td>0.416</td>
                          <td>0.339</td>
                          <td>0.555</td>
                          <td>0.371</td>
                          <td>0.322</td>
                          <td>0.674</td>
                          <td>0.419</td>
                          <td>0.345</td>
                          <td>0.717</td>
                          <td>0.507</td>
                          <td>0.390</td>
                          <td>0.638</td>
                          <td>0.423</td>
                          <td>0.345</td>
                        </tr>
                        <tr>
                          <th>Gemini + SD 3</th>
                          <td>0.764</td>
                          <td>0.590</td>
                          <td>0.478</td>
                          <td>0.729</td>
                          <td>0.589</td>
                          <td>0.453</td>
                          <td>0.725</td>
                          <td>0.540</td>
                          <td>0.452</td>
                          <td>0.715</td>
                          <td>0.556</td>
                          <td>0.452</td>
                          <td>0.785</td>
                          <td>0.640</td>
                          <td>0.485</td>
                          <td>0.744</td>
                          <td>0.583</td>
                          <td>0.464</td>
                        </tr>
                        <tr>
                          <th>Claude + SD 3</th>
                          <td>0.744</td>
                          <td>0.578</td>
                          <td>0.454</td>
                          <td>0.751</td>
                          <td>0.586</td>
                          <td>0.456</td>
                          <td>0.675</td>
                          <td>0.497</td>
                          <td>0.408</td>
                          <td>0.745</td>
                          <td>0.556</td>
                          <td>0.441</td>
                          <td>0.795</td>
                          <td>0.629</td>
                          <td>0.478</td>
                          <td>0.742</td>
                          <td>0.569</td>
                          <td>0.447</td>
                        </tr>
                        <tr>
                          <th>Gemini + SD 3.5</th>
                          <td>0.786</td>
                          <td>0.615</td>
                          <td>0.500</td>
                          <td>0.756</td>
                          <td>0.591</td>
                          <td>0.473</td>
                          <td>0.759</td>
                          <td>0.558</td>
                          <td>0.459</td>
                          <td>0.789</td>
                          <td>0.564</td>
                          <td>0.441</td>
                          <td>0.780</td>
                          <td>0.610</td>
                          <td>0.460</td>
                          <td>0.774</td>
                          <td>0.588</td>
                          <td>0.467</td>
                        </tr>
                        <tr>
                          <th><b>Claude + SD 3.5</b></th>
                          <td>0.767</td>
                          <td>0.563</td>
                          <td>0.469</td>
                          <td>0.777</td>
                          <td>0.598</td>
                          <td>0.472</td>
                          <td>0.700</td>
                          <td>0.506</td>
                          <td>0.406</td>
                          <td>0.789</td>
                          <td>0.625</td>
                          <td>0.466</td>
                          <td>0.790</td>
                          <td>0.654</td>
                          <td>0.498</td>
                          <td><b>0.765</b></td>
                          <td><b>0.589</b></td>
                          <td><b>0.462</b></td>
                        </tr>
                        <tr>
                          <th>Ground Truth</th>
                          <th>-</th>
                          <td>0.711</td>
                          <td><b>0.797</b></td>
                          <td><b>0.712</b></td>
                          <td>0.751</td>
                          <td><b>0.780</b></td>
                          <td><b>0.748</b></td>
                          <td>0.651</td>
                          <td><b>0.714</b></td>
                          <td><b>0.624</b></td>
                          <td>0.772</td>
                          <td><b>0.722</b></td>
                          <td><b>0.692</b></td>
                          <td><b>0.780</b></td>
                          <td><b>0.820</b></td>
                          <td><b>0.756</b></td>
                          <td>0.733</td>
                          <td><b>0.767</b></td>
                          <td><b>0.706</b></td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>

                <div title="MLLM-as-a-Judge Validation" class="lib_examples" id="BoardPanel3" style="display: block;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                  </md-block>
                  <!-- </div> -->

                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Model</th>
                          <th colspan="3">Real-world Data</th>
                          <th colspan="3">Synthetic Data</th>
                        </tr>
                        <tr>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                          <th>IQ</th>
                          <th>IF</th>
                          <th>SF</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th>Gemini-2.0-Flash</th>
                          <td>0.385</td>
                          <td>0.422</td>
                          <td>0.354</td>
                          <td>0.369</td>
                          <td>0.627</td>
                          <td>0.588</td>
                        </tr>
                        <tr>
                          <th>GPT-4o-mini</th>
                          <td>0.466</td>
                          <td>0.530</td>
                          <td>0.514</td>
                          <td>0.438</td>
                          <td>0.632</td>
                          <td>0.616</td>
                        </tr>
                        <tr>
                          <th>GPT-4o</th>
                          <td>0.432</td>
                          <td>0.624</td>
                          <td>0.613</td>
                          <td>0.406</td>
                          <td>0.668</td>
                          <td>0.659</td>
                        </tr>
                        <tr>
                          <th><b>Human-Human</b></th>
                          <td><b>0.589</b></td>
                          <td><b>0.665</b></td>
                          <td><b>0.571</b></td>
                          <td><b>0.629</b></td>
                          <td><b>0.721</b></td>
                          <td><b>0.694</b></td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>

                <div title="Ablation Study" class="lib_examples" id="BoardPanel4" style="display: none;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Notice: Switch order = switch the image input order. w/o caption = delete the caption in input instructions.
                  </md-block>
                  <!-- </div> -->

                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Model</th>
                          <th rowspan="2">Setting</th>
                          <th colspan="2">Image Quality</th>
                          <th colspan="10">Reference Fidelity</th>
                        </tr>
                        <tr>
                          <th>FID↓</th>
                          <th>Aesthetic↑</th>
                          <th>BBox↑</th>
                          <th>Semantic Map↑</th>
                          <th>Mask↑</th>
                          <th>Depth↓</th>
                          <th>Canny↓</th>
                          <th>Sketch↓</th>
                          <th>Caption↑</th>
                          <th>Pose↑</th>
                          <th>Subject↑</th>
                          <th>Art Style↑</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th rowspan="3">OmniGen</th>
                          <th>Original</th>
                          <td>0.114</td>
                          <td>0.588</td>
                          <td>0.267</td>
                          <td>0.272</td>
                          <td>0.273</td>
                          <td>0.062</td>
                          <td>0.098</td>
                          <td>0.216</td>
                          <td>0.014</td>
                          <td>0.193</td>
                          <td>0.735</td>
                          <td>0.565</td>
                        </tr>
                        <tr>
                          <th>Switch order</th>
                          <td>0.114</td>
                          <td>0.579</td>
                          <td>0.382</td>
                          <td>0.315</td>
                          <td>0.290</td>
                          <td>0.068</td>
                          <td>0.105</td>
                          <td>0.219</td>
                          <td>0.005</td>
                          <td>0.195</td>
                          <td>0.737</td>
                          <td>0.556</td>
                        </tr>
                        <tr>
                          <th>w/o caption</th>
                          <td>0.120</td>
                          <td>0.534</td>
                          <td>0.180</td>
                          <td>0.308</td>
                          <td>0.272</td>
                          <td>0.081</td>
                          <td>0.137</td>
                          <td>0.191</td>
                          <td>-</td>
                          <td>0.202</td>
                          <td>0.669</td>
                          <td>0.581</td>
                        </tr>
                        <tr>
                          <th rowspan="3">ACE</th>
                          <th>Original</th>
                          <td>0.114</td>
                          <td>0.597</td>
                          <td>0.326</td>
                          <td>0.296</td>
                          <td>0.311</td>
                          <td>0.037</td>
                          <td>0.089</td>
                          <td>0.120</td>
                          <td>0.089</td>
                          <td>0.191</td>
                          <td>0.715</td>
                          <td>0.552</td>
                        </tr>
                        <tr>
                          <th>Switch order</th>
                          <td>0.112</td>
                          <td>0.598</td>
                          <td>0.303</td>
                          <td>0.243</td>
                          <td>0.386</td>
                          <td>0.077</td>
                          <td>0.105</td>
                          <td>0.222</td>
                          <td>0.036</td>
                          <td>0.191</td>
                          <td>0.802</td>
                          <td>0.600</td>
                        </tr>
                        <tr>
                          <th>w/o caption</th>
                          <td>0.114</td>
                          <td>0.567</td>
                          <td>0.231</td>
                          <td>0.470</td>
                          <td>0.481</td>
                          <td>0.019</td>
                          <td>0.111</td>
                          <td>0.069</td>
                          <td>-</td>
                          <td>0.197</td>
                          <td>0.657</td>
                          <td>0.567</td>
                        </tr>
                        <tr>
                          <th rowspan="3">ChatDiT</th>
                          <th>Original</th>
                          <td>0.107</td>
                          <td>0.560</td>
                          <td>0.147</td>
                          <td>0.160</td>
                          <td>0.261</td>
                          <td>0.098</td>
                          <td>0.065</td>
                          <td>0.227</td>
                          <td>0.022</td>
                          <td>0.194</td>
                          <td>0.818</td>
                          <td>0.541</td>
                        </tr>
                        <tr>
                          <th>Switch order</th>
                          <td>0.105</td>
                          <td>0.574</td>
                          <td>0.125</td>
                          <td>0.150</td>
                          <td>0.284</td>
                          <td>0.092</td>
                          <td>0.063</td>
                          <td>0.220</td>
                          <td>0.022</td>
                          <td>0.194</td>
                          <td>0.830</td>
                          <td>0.556</td>
                        </tr>
                        <tr>
                          <th>w/o caption</th>
                          <td>0.096</td>
                          <td>0.550</td>
                          <td>0.142</td>
                          <td>0.132</td>
                          <td>0.278</td>
                          <td>0.113</td>
                          <td>0.066</td>
                          <td>0.196</td>
                          <td>-</td>
                          <td>0.202</td>
                          <td>0.836</td>
                          <td>0.553</td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="Empirical Result">
    <div class="container is-max-desktop">
      <div class="featurecard-container">
        <!-- Trustworthiness and Utility -->
        <h1 class="title">Empirical Results</h1>
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Compositional framework exceeds in image quality, while failing to maintain consistency on real-world cases.</h2>
          </div>
          <div class="description">
            <p>
              LLM+SD combinations achieve the highest image quality scores, with Claude + SD3.5 reaching 0.774, occasionally surpassing ground truth. However, all compositional frameworks consistently underperform in instruction following and source fidelity.
              While ground truth achieves 0.767 and 0.706 for IF and SF respectively, Claude + SD3.5 only reaches 0.589 and 0.462, indicating that
              separated perceptor-generator architecture fundamentally compromises complex visual instruction execution.
            </p>
          </div>
        </div>

        <!-- Alignment of LLMs -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Unified models struggled with generation quality and handling real-world images.</h2>
          </div>
          <div class="description">
            <p>
              Although unified models theoretically
            end-to-end advantage contributes to maintaining consistency, they
            underperform in fidelity preservation. OmniGen’s performance in various metrics even approaches some
            compositional frameworks that generate images with state-of-theart diffusion models, demonstrating its effectiveness in balancing
            quality with instruction adherence. However, all models still fall
            short when compared with the golden answer (created with professional software), highlighting significant room for improvement in
            real-world image generation scenarios.
            </p>
          </div>
        </div>

        <!-- Performance Gap in Trustworthiness -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Controllable image generation from multiple references is challenging.</h2>
          </div>
          <div class="description">
            <p>
              Even advanced models like ACE, despite strong performance in specific areas (Bbox: 0.219, Pose: 0.090), show substantial gaps in reference fidelity compared to Ground Truth. While unified end-to-end architectures offer greater potential than compositional frameworks, both struggle with complex reference combinations or image generation without captions, highlighting the
              need for improved generalization in multi-image generation.
            </p>
          </div>
        </div>


        <!-- Transparency in Trustworthiness -->
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>Models show strong and varied preferences for reference formats.</h2>
          </div>
          <div class="description">
            <p>
              Our ablation study presents results investigating how different input formats for Bounding Box (BBox), Depth,
              and Mask conditions affect the generation performance of three
              models. There is no universally superior format that works best
              across all tested models. Instead, each model often exhibits a distinct preference. ACE and ChatDiT show more robust performance
              on the depth and mask format. For Depth MSE, ACE performs significantly better with “ori depth," whereas OmniGen and ChatDiT
              show slightly better or comparable performance with “color depth".</p>

          </div>
        </div>
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>Input order primarily influences specific conditional fidelities rather than global image quality.</h2>
          </div>
          <div class="description">
            <p>
              Switching the input order resulted in only minor FID improvements or no change for the models. However, this operation had more
              substantial and often model-specific impacts on adherence to particular conditions. For example, ACE’s depth error and sketch error
              both increased dramatically when the order was switched. These
              observations suggest that the sequence of processing conditions
              is more critical for controlling specific visual attributes than for
              overall image realism as measured by FID. The presence of captions
              also improves depth fidelity and aesthetic quality across all models.
              For instance, ACE’s depth error significantly increases when captions are removed. However, for semantic map fidelity, OmniGen
              and ACE perform better without captions. Similarly, sketch fidelity
              improves for all three models when captions are absent, with ACE
              showing a notable reduction in sketch error.</p>

          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="Acknoledgement">
    <div class="container is-max-desktop content">
      <h1 class="supportTitle">Acknowledgement</h1>
      <md-block>
        Many thanks to Jieyu Zhang for his invaluable effort in this project.
      </md-block>
    </div>
  </section>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h1 class="title">BibTeX</h1>
      <pre><code></code></pre>
    </div>
  </section>
  <div class="content">
    <div id="supportContainer">
      <h1 class="supportTitle">MultiRef Team</h1>
      <br>

      <div id="logoContainer">
        <img src="img/logos/UW.png" alt="School 1" class="schoolLogo">
        <img src="img/logos/HUST.png" alt="School 2" class="schoolLogo">

      </div>


    </div>
  </div>
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.

            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>